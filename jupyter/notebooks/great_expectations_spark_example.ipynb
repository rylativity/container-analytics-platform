{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df68cc7d-3bf9-4072-8cbe-8ac5434b5c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.batch import BatchRequest, RuntimeBatchRequest\n",
    "from ruamel import yaml\n",
    "import pyspark\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89b957-44e8-42e1-bcb1-2fe11e34da55",
   "metadata": {},
   "source": [
    "## Get Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89dde78-9406-4018-904c-2bbd30ecc4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'PATH': '/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
       "        'HOSTNAME': '7d38694ece0b',\n",
       "        'S3_ENDPOINT': 'http://minio:9000',\n",
       "        'S3_BUCKET': 'test',\n",
       "        'S3_ACCESS_KEY': 'jupyteraccesskey',\n",
       "        'S3_SECRET_KEY': 'jupytersupersecretkey',\n",
       "        'LANG': 'C.UTF-8',\n",
       "        'GPG_KEY': 'A035C8C19219BA821ECEA86B64E628F8D684696D',\n",
       "        'PYTHON_VERSION': '3.11.0',\n",
       "        'PYTHON_PIP_VERSION': '22.3',\n",
       "        'PYTHON_SETUPTOOLS_VERSION': '65.5.0',\n",
       "        'PYTHON_GET_PIP_URL': 'https://github.com/pypa/get-pip/raw/66030fa03382b4914d4c4d0896961a0bdeeeb274/public/get-pip.py',\n",
       "        'PYTHON_GET_PIP_SHA256': '1e501cf004eac1b7eb1f97266d28f995ae835d30250bec7f8850562703067dc6',\n",
       "        'HOME': '/root',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'JPY_SESSION_NAME': 'c9b204d3-ec1b-464b-b83f-16e52622e65d',\n",
       "        'JPY_PARENT_PID': '1',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ \n",
    "## Should see S3_ENDPOINT, S3_ACCESS_KEY, and S3_SECRET_KEY environment varibles.\n",
    "# These environment variables are set in the docker-compose.yml, and the service account used by PySpark\n",
    "#> to read from and write to Minio are created by the minio-init container defined in docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476cfaea-2226-48b4-853f-efceb0f791aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S3_ACCESS_KEY = os.environ.get(\"S3_ACCESS_KEY\")\n",
    "S3_BUCKET = os.environ.get(\"S3_BUCKET\")\n",
    "S3_SECRET_KEY = os.environ.get(\"S3_SECRET_KEY\")\n",
    "S3_ENDPOINT = os.environ.get(\"S3_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46feb19-387b-48f5-9751-85f7b5c4e63f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a68d1edc-b513-445f-a289-261cf5609cc2;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound io.delta#delta-core_2.12;2.1.0 in central\n",
      "\tfound io.delta#delta-storage;2.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.1/hadoop-aws-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.3.1!hadoop-aws.jar (91ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-core_2.12/2.1.0/delta-core_2.12-2.1.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-core_2.12;2.1.0!delta-core_2.12.jar (343ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.901!aws-java-sdk-bundle.jar (19684ms)\n",
      "downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...\n",
      "\t[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (56ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-storage/2.1.0/delta-storage-2.1.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-storage;2.1.0!delta-storage.jar (22ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.8/antlr4-runtime-4.8.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.8!antlr4-runtime.jar (42ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.9.13!jackson-core-asl.jar (34ms)\n",
      ":: resolution report :: resolve 3376ms :: artifacts dl 20290ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tio.delta#delta-core_2.12;2.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   7   |   7   |   0   ||   7   |   7   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a68d1edc-b513-445f-a289-261cf5609cc2\n",
      "\tconfs: [default]\n",
      "\t7 artifacts copied, 0 already retrieved (192837kB/145ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 01:47:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# This cell may take some time to run the first time, as it must download the necessary spark jars\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "## IF YOU ARE USING THE SPARK CONTAINERS, UNCOMMENT THE LINE BELOW TO OFFLOAD EXECUTION OF SPARK TASKS TO SPARK CONTAINERS\n",
    "#conf.setMaster(\"spark://spark:7077\")\n",
    "\n",
    "conf.set(\"spark.jars.packages\", 'org.apache.hadoop:hadoop-aws:3.3.1,io.delta:delta-core_2.12:2.1.0')\n",
    "# conf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider')\n",
    "conf.set('spark.hadoop.fs.s3a.endpoint', S3_ENDPOINT)\n",
    "conf.set('spark.hadoop.fs.s3a.access.key', S3_ACCESS_KEY)\n",
    "conf.set('spark.hadoop.fs.s3a.secret.key', S3_SECRET_KEY)\n",
    "conf.set('spark.hadoop.fs.s3a.path.style.access', \"true\")\n",
    "conf.set(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "# sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82334983-1c2a-4c99-8c38-4c107b1eab47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f935e04e-9802-4a52-8e8d-25bcab8be52b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 01:47:50 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "delta_table_name = \"appl_stock_delta_table\"\n",
    "df = spark.read.format(\"delta\").load(f\"s3a://{S3_BUCKET}/{delta_table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a99a19-7e1e-453c-bccc-8c90ba39885b",
   "metadata": {},
   "source": [
    "## Prepare Great Expectations Context and Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0cbe41-a414-42d1-9b2a-9f4afc16ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 01:48:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "context = gx.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fcdbbd8-cb06-441a-a5ee-485c084cb050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasource_name = \"delta_lake\"\n",
    "\n",
    "config = f\"\"\"\n",
    "name: {datasource_name}\n",
    "class_name: Datasource\n",
    "execution_engine:\n",
    "  class_name: SparkDFExecutionEngine\n",
    "data_connectors:\n",
    "  default_runtime_data_connector_name:\n",
    "    class_name: RuntimeDataConnector\n",
    "    batch_identifiers:\n",
    "      - batch_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55c25ab-132b-4a92-a96d-6b3571d39693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: SparkDFExecutionEngine\n",
      "Data Connectors:\n",
      "\tdefault_runtime_data_connector_name:RuntimeDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (0 of 0):\n",
      "\t\tNote : RuntimeDataConnector will not have data_asset_names until they are passed in through RuntimeBatchRequest\n",
      "\n",
      "\tUnmatched data_references (0 of 0): []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7fc93ca0e310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.test_yaml_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3016935-af03-4e1d-8e3b-0216a8a37980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7fc93ca11fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_datasource(**yaml.load(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24887e96-b715-4ed5-a6ff-3af6f9a1fc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=datasource_name,\n",
    "    data_connector_name=\"default_runtime_data_connector_name\",\n",
    "    data_asset_name=\"APPL_TABLE\",  # this is the name of the table you want to retrieve\n",
    "    batch_identifiers={\"batch_id\":\"default_identifier\"},\n",
    "    runtime_parameters={\"batch_data\":df}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "534bd519-5597-4799-b63f-0b400a371963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context.create_expectation_suite(\n",
    "    expectation_suite_name=\"test_suite\", overwrite_existing=True\n",
    ")\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request, expectation_suite_name=\"test_suite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79872462-37ff-4629-a1f9-746f0fe19596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643c8e3c45fe4df8acee2cef074c53bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {},\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_to_exist(\"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2df9b05-e4a0-4f12-bcd1-e410e7fc6840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950120480fdd438cb642027c3918cd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"observed_value\": 90.279999\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_min_to_be_between(\"Close\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53dffef3-0f40-47fd-98c5-8adf988b74bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303386a7e7b04adea2132a18d6bc0b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-01</td>\n",
       "      <td>397.779999</td>\n",
       "      <td>399.500011</td>\n",
       "      <td>392.369995</td>\n",
       "      <td>396.749989</td>\n",
       "      <td>153209000</td>\n",
       "      <td>51.402750</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-02</td>\n",
       "      <td>397.650009</td>\n",
       "      <td>397.900002</td>\n",
       "      <td>388.350010</td>\n",
       "      <td>388.909996</td>\n",
       "      <td>159884900</td>\n",
       "      <td>50.387004</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-03</td>\n",
       "      <td>390.980003</td>\n",
       "      <td>393.549995</td>\n",
       "      <td>382.239990</td>\n",
       "      <td>392.570000</td>\n",
       "      <td>183127000</td>\n",
       "      <td>50.861193</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-04</td>\n",
       "      <td>389.410007</td>\n",
       "      <td>391.320011</td>\n",
       "      <td>377.349998</td>\n",
       "      <td>377.369999</td>\n",
       "      <td>217851900</td>\n",
       "      <td>48.891888</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>380.440002</td>\n",
       "      <td>383.499992</td>\n",
       "      <td>362.570007</td>\n",
       "      <td>373.620007</td>\n",
       "      <td>301147700</td>\n",
       "      <td>48.406040</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close     Volume  \\\n",
       "0  2011-08-01  397.779999  399.500011  392.369995  396.749989  153209000   \n",
       "1  2011-08-02  397.650009  397.900002  388.350010  388.909996  159884900   \n",
       "2  2011-08-03  390.980003  393.549995  382.239990  392.570000  183127000   \n",
       "3  2011-08-04  389.410007  391.320011  377.349998  377.369999  217851900   \n",
       "4  2011-08-05  380.440002  383.499992  362.570007  373.620007  301147700   \n",
       "\n",
       "   Adj_Close  Month  Year  \n",
       "0  51.402750      8  2011  \n",
       "1  50.387004      8  2011  \n",
       "2  50.861193      8  2011  \n",
       "3  48.891888      8  2011  \n",
       "4  48.406040      8  2011  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50671f17-9911-456d-86ff-c980efe3ed64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
